# -*- coding: utf-8 -*-
"""Breast Cancer.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1eKiw2sKjD78DgIGDBJpB_LKT3ZeRpdyf
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

data=pd.read_csv('https://raw.githubusercontent.com/Adithya-ScriptKindle/Breast-Cancer-Prediction/main/data.csv')

dt=pd.DataFrame(data)

dt.shape
print(dt.info())

dt.isna().sum()

df=dt.dropna(axis=1)

df= df.drop(['id'], axis = 1)


print(df.info())

X=pd.DataFrame(df)
X=X.drop(['diagnosis'],axis=1)
y=df['diagnosis']
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=0)

#from sklearn.preprocessing import StandardScaler
#sc = StandardScaler()
#X_train = sc.fit_transform(X_train)
#X_test = sc.fit_transform(X_test)

from sklearn.linear_model import LogisticRegression
Log = LogisticRegression()
Log.fit(X_train,y_train)
y_p1=Log.predict(X_test)
from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, y_p)
print("Accuracy using Logistic Regresssion: %f"%acc)

from sklearn.tree import DecisionTreeClassifier
DTC= DecisionTreeClassifier(random_state = 0)
DTC.fit(X_train,y_train)
y_p2=DTC.predict(X_test)
from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, y_p)
print("Accuracy using Decision Tree Classifier: %f"%acc)

from sklearn.ensemble import RandomForestClassifier
RFC= RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)
RFC.fit(X_train,y_train)
y_p3=RFC.predict(X_test)
from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, y_p1)
print("Accuracy using Random Forest Classifier: %f"%acc)

from sklearn.neighbors import KNeighborsClassifier
KNN1= KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p = 2)
KNN1.fit(X_train,y_train)
y_p4=KNN1.predict(X_test)
from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, y_p)
print("Accuracy using KNeighbors Classifiers: %f"%acc)

from sklearn.naive_bayes import GaussianNB
GNB= GaussianNB()
GNB.fit(X_train,y_train)
y_p5=GNB.predict(X_test)
from sklearn.metrics import accuracy_score
acc = accuracy_score(y_test, y_p)
print("Accuracy using GaussianNB Classifiers: %f"%acc)

from sklearn.metrics import confusion_matrix
cm1 = confusion_matrix(y_test, y_p1)
cm2 = confusion_matrix(y_test, y_p2)
cm3 = confusion_matrix(y_test, y_p3)
cm4 = confusion_matrix(y_test, y_p4)
cm5 = confusion_matrix(y_test, y_p5)

print("Confusion Matrix Of Logistic Regression")
labels =['Pr 0', 'Pr 1']
print(*labels)
for line in cm1:
  print(*line)

print("Confusion Matrix Of Decision Tree Classifier")
labels =['Pr 0', 'Pr 1']
print(*labels)
for line in cm2:
  print(*line)

print("Confusion Matrix Of Random Forest Classifier")
labels =['Pr 0', 'Pr 1']
print(*labels)
for line in cm3:
  print(*line)

print("Confusion Matrix Of KNeighbors Classifiers")
labels =['Pr 0', 'Pr 1']
print(*labels)
for line in cm4:
  print(*line)

print("Confusion Matrix Of GaussianNB Classifier")
labels =['Pr 0', 'Pr 1']
print(*labels)
for line in cm5:
  print(*line)

Log.predict([[17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189]])

DTC.predict([[17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189]])

RFC.predict([[17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189]])

KNN1.predict([[17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189]])

GNB.predict([[17.99,10.38,122.8,1001,0.1184,0.2776,0.3001,0.1471,0.2419,0.07871,1.095,0.9053,8.589,153.4,0.006399,0.04904,0.05373,0.01587,0.03003,0.006193,25.38,17.33,184.6,2019,0.1622,0.6656,0.7119,0.2654,0.4601,0.1189]])